{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edgeprobe Aggregate Analysis\n",
    "\n",
    "This notebook is intended to be run on the output of the [`analyze_runs.py`](analyze_runs.py) script; run that on a folder of experiments to produce a `scores.tsv` file that can be loaded here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re, json\n",
    "from importlib import reload\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import analysis\n",
    "reload(analysis)\n",
    "\n",
    "tasks = analysis.TASKS\n",
    "exp_types = analysis.EXP_TYPES\n",
    "palette = analysis.EXP_PALETTE\n",
    "\n",
    "task_sort_key = analysis.task_sort_key\n",
    "exp_type_sort_key = analysis.exp_type_sort_key\n",
    "\n",
    "from scipy.special import logsumexp\n",
    "from scipy.stats import entropy\n",
    "\n",
    "def softmax(x, axis=None):\n",
    "    return np.exp(x - logsumexp(x, axis=axis, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.2.0.min.js\"];\n",
       "  var css_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.css\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.2.0.min.js\"];\n  var css_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.css\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bokeh\n",
    "import bokeh.plotting as bp\n",
    "bp.output_notebook()\n",
    "\n",
    "import datetime\n",
    "import socket\n",
    "def get_compact_timestamp():\n",
    "    now = datetime.datetime.now()\n",
    "    return now.strftime(\"%Y%m%d.%H%M%S\")\n",
    "\n",
    "def _save_figure_to_bucket(fig, name, title=None, export_format=\"html\"):\n",
    "    now = get_compact_timestamp()\n",
    "    fname = f\"{name}.{now:s}.{export_format}\"\n",
    "    title = title or name\n",
    "    if fname.endswith('.png'):\n",
    "        bokeh.io.export_png(p, os.path.join(\"/tmp\", fname))\n",
    "    else:\n",
    "        bp.save(p, os.path.join(\"/tmp\", fname), title=title, \n",
    "                resources=bokeh.resources.CDN)\n",
    "    hostname = socket.gethostname()\n",
    "    GCP_PROJECT=\"edge-probing\"\n",
    "    !gsutil cp /tmp/$fname gs://$GCP_PROJECT/$hostname/plots/$fname\n",
    "    !gsutil acl ch -u AllUsers:R gs://$GCP_PROJECT/$hostname/plots/$fname\n",
    "    url = f\"https://storage.googleapis.com/{GCP_PROJECT}/{hostname}/plots/{fname}\"\n",
    "    print(f\"Public URL: {url}\")\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_COLS = ['run', 'task', 'split']\n",
    "\n",
    "def agg_label_group(df, task_predicate, label_predicate, group_name):\n",
    "    agg_map = {k:\"sum\" for k in df.columns if k.endswith(\"_count\")}\n",
    "    mask = df['task'].map(task_predicate) & df['label'].map(label_predicate)\n",
    "    sdf = df[mask].groupby(by=ID_COLS).agg(agg_map).reset_index()\n",
    "    sdf['label'] = group_name\n",
    "    return sdf\n",
    "\n",
    "def agg_stratifier_group(df, stratifier, key_predicate, group_name):\n",
    "    agg_map = {k:\"sum\" for k in df.columns if k.endswith(\"_count\")}\n",
    "    # Use this for short-circuit evaluation, so we don't call key_predicate on invalid keys\n",
    "    mask = [(s == stratifier and key_predicate(key)) \n",
    "            for s, key in zip(df['stratifier'], df['stratum_key'])]\n",
    "    sdf = df[mask].groupby(by=ID_COLS).agg(agg_map).reset_index()\n",
    "    sdf['label'] = group_name\n",
    "    return sdf    \n",
    "\n",
    "def load_scores_file(filename, tag=None, seed=None):\n",
    "    df = pd.read_csv(filename, sep=\"\\t\", header=0)\n",
    "    df.drop(['Unnamed: 0'], axis='columns', inplace=True)\n",
    "    # df['task_raw'] = df['task'].copy()\n",
    "    df['task'] = df['task'].map(analysis.clean_task_name)\n",
    "    if not \"stratifier\" in df.columns:\n",
    "        df[\"stratifier\"] = None\n",
    "    if not \"stratum_key\" in df.columns:\n",
    "        df[\"stratum_key\"] = 0\n",
    "        \n",
    "    ###\n",
    "    # Add additional custom aggregations\n",
    "    _eg = []\n",
    "    # SRL core, non-core, and cleaned micro F1\n",
    "    _eg.append(agg_label_group(df, analysis.is_srl_task, analysis.is_core_role, \"_core_\"))\n",
    "    _eg.append(agg_label_group(df, analysis.is_srl_task, analysis.is_non_core_role, \"_non_core_\"))\n",
    "    _eg.append(agg_label_group(df, analysis.is_srl_task, analysis.is_core_or_noncore, \"_clean_micro_\"))\n",
    "    # Constituents: split into POS, nonterminals\n",
    "    _eg.append(agg_stratifier_group(df, 'info.height', lambda x: int(x) == 1, \"_pos_\"))\n",
    "    _eg.append(agg_stratifier_group(df, 'info.height', lambda x: int(x) > 1, \"_nonterminal_\"))\n",
    "    # Relations: ignore negative class (no_relation)\n",
    "    _eg.append(agg_label_group(df, analysis.is_relation_task, analysis.is_positive_relation, \"_clean_micro_\"))\n",
    "    df = pd.concat([df] + _eg, ignore_index=True, sort=False)\n",
    "    \n",
    "    df.insert(0, \"exp_name\", df['run'].map(lambda p: os.path.basename(os.path.dirname(p.strip(\"/\")))))\n",
    "    df.insert(1, \"exp_type\", df['exp_name'].map(analysis.get_exp_type))\n",
    "    df.insert(1, \"layer_num\", df['exp_name'].map(analysis.get_layer_num))\n",
    "    if tag is not None:\n",
    "        df.insert(0, \"tag\", tag)\n",
    "    df.insert(1, \"seed\", seed)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify score files and load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rel-semeval' 'spr2' 'coref-ontonotes' 'ner-ontonotes' 'srl-ontonotes']\n",
      "['bert-base-uncased-lex' 'bert-base-uncased-mix']\n"
     ]
    }
   ],
   "source": [
    "score_files = []\n",
    "# Add (tag, path/to/scores.tsv) tuples here; results will be concatenated.\n",
    "score_files = [\n",
    "    (\"base\", \"/nfs/jiant/exp/iftenney/20190721-test-ep-bert/stats.tsv\"),\n",
    "    (\"base\", \"/nfs/jiant/exp/iftenney/20190721-test-ep-bert-medium/stats.tsv\"),\n",
    "]\n",
    "dfs = []\n",
    "for tag, score_file in score_files:\n",
    "    df = load_scores_file(score_file, tag=tag)\n",
    "    dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True, sort=False)\n",
    "def _format_display_col(exp_type, layer_num, tag):\n",
    "    ret = exp_type\n",
    "    if layer_num:\n",
    "        ret += f\"-{layer_num}\"\n",
    "    if tag:\n",
    "        ret += f\" ({tag})\"\n",
    "    return ret\n",
    "\n",
    "df['display_col'] = list(map(_format_display_col, df.exp_type, df.layer_num, df.tag))\n",
    "print(df['task'].unique())\n",
    "print(df['exp_type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.score_from_confusion_matrix(df)\n",
    "\n",
    "def _get_final_score(row):\n",
    "    return row['f1_score'], row['f1_errn95']\n",
    "\n",
    "df['score'], df['score_errn95'] = zip(*(_get_final_score(row) for i, row in df.iterrows()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For DPR, we need to average across multiple runs to get a good estimate of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['task'] == 'dpr'\n",
    "mask &= df['label'] != \"__run_info__\"\n",
    "mask &= df['seed'].notnull()\n",
    "gb_cols = [\"tag\", \"exp_name\", \"exp_type\", \"task\", \"label\", \"split\", \"display_col\"]\n",
    "gb = df[mask].groupby(by=gb_cols)\n",
    "new_rows = []\n",
    "for key, idxs in gb.groups.items():\n",
    "    new_row = dict(zip(gb_cols, key))\n",
    "    new_row[\"seed\"] = \"_mean_\"\n",
    "    new_row[\"score\"] = df.loc[idxs, \"score\"].mean()\n",
    "    new_row[\"score_errn95\"] = 1.96 * np.sqrt(df.loc[idxs, \"score\"].var()/len(idxs))\n",
    "    new_rows.append(new_row)\n",
    "    \n",
    "agg_df = pd.DataFrame.from_records(new_rows)\n",
    "df = pd.concat([df, agg_df], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For SemEval 2010 Task 8, the official metric is macro-averaged F1 over non-Other labels. Compute this so we can compare to SOTA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run,split,score\n",
      "/nfs/jiant/exp/iftenney/20190721-test-ep-bert//bert-base-uncased-lex-edges-rel-semeval/run,test,0.5261\n",
      "/nfs/jiant/exp/iftenney/20190721-test-ep-bert//bert-base-uncased-lex-edges-rel-semeval/run,val,0.5013\n",
      "/nfs/jiant/exp/iftenney/20190721-test-ep-bert//bert-base-uncased-mix-edges-rel-semeval/run,test,0.7442\n",
      "/nfs/jiant/exp/iftenney/20190721-test-ep-bert//bert-base-uncased-mix-edges-rel-semeval/run,val,0.7531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mask = df['task'] == 'rel-semeval'\n",
    "mask &= df['split'].notnull()\n",
    "mask &= df['label'].map(analysis.is_positive_relation)\n",
    "_id_cols = ['run', 'split']\n",
    "_agg_cols = ['score']\n",
    "gb = df[mask][_id_cols + _agg_cols].groupby(_id_cols)\n",
    "afd = gb.agg('mean')\n",
    "afd = afd.reset_index()\n",
    "\n",
    "csv_args = dict(float_format=\"%.4f\")\n",
    "print(afd.to_csv(index=False, **csv_args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute clean metrics for each task\n",
    "\n",
    "For most tasks this is just the micro or macro average F1, but we need to ignore the 0 label for coref, and drop references and continuations for SRL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>seed</th>\n",
       "      <th>exp_name</th>\n",
       "      <th>layer_num</th>\n",
       "      <th>exp_type</th>\n",
       "      <th>run</th>\n",
       "      <th>task</th>\n",
       "      <th>split</th>\n",
       "      <th>label</th>\n",
       "      <th>fn_count</th>\n",
       "      <th>...</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy_errn95</th>\n",
       "      <th>precision_errn95</th>\n",
       "      <th>recall_errn95</th>\n",
       "      <th>f1_errn95</th>\n",
       "      <th>score</th>\n",
       "      <th>score_errn95</th>\n",
       "      <th>display_row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base</td>\n",
       "      <td>None</td>\n",
       "      <td>bert-base-uncased-lex-edges-rel-semeval</td>\n",
       "      <td>None</td>\n",
       "      <td>bert-base-uncased-lex</td>\n",
       "      <td>/nfs/jiant/exp/iftenney/20190721-test-ep-bert/...</td>\n",
       "      <td>rel-semeval</td>\n",
       "      <td>test</td>\n",
       "      <td>_clean_micro_</td>\n",
       "      <td>1153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.490499</td>\n",
       "      <td>0.580696</td>\n",
       "      <td>0.001578</td>\n",
       "      <td>0.022482</td>\n",
       "      <td>0.020597</td>\n",
       "      <td>0.021498</td>\n",
       "      <td>0.580696</td>\n",
       "      <td>0.021498</td>\n",
       "      <td>rel-semeval-_clean_micro_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>base</td>\n",
       "      <td>None</td>\n",
       "      <td>bert-base-uncased-mix-edges-rel-semeval</td>\n",
       "      <td>None</td>\n",
       "      <td>bert-base-uncased-mix</td>\n",
       "      <td>/nfs/jiant/exp/iftenney/20190721-test-ep-bert/...</td>\n",
       "      <td>rel-semeval</td>\n",
       "      <td>test</td>\n",
       "      <td>_clean_micro_</td>\n",
       "      <td>494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864614</td>\n",
       "      <td>0.781706</td>\n",
       "      <td>0.821072</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.014825</td>\n",
       "      <td>0.017020</td>\n",
       "      <td>0.015847</td>\n",
       "      <td>0.821072</td>\n",
       "      <td>0.015847</td>\n",
       "      <td>rel-semeval-_clean_micro_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>base</td>\n",
       "      <td>None</td>\n",
       "      <td>bert-base-uncased-lex-edges-spr2</td>\n",
       "      <td>None</td>\n",
       "      <td>bert-base-uncased-lex</td>\n",
       "      <td>/nfs/jiant/exp/iftenney/20190721-test-ep-bert/...</td>\n",
       "      <td>spr2</td>\n",
       "      <td>test</td>\n",
       "      <td>_micro_avg_</td>\n",
       "      <td>846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.829507</td>\n",
       "      <td>0.803940</td>\n",
       "      <td>0.816523</td>\n",
       "      <td>0.006187</td>\n",
       "      <td>0.011398</td>\n",
       "      <td>0.011846</td>\n",
       "      <td>0.011618</td>\n",
       "      <td>0.816523</td>\n",
       "      <td>0.011618</td>\n",
       "      <td>spr2-_micro_avg_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>base</td>\n",
       "      <td>None</td>\n",
       "      <td>bert-base-uncased-mix-edges-spr2</td>\n",
       "      <td>None</td>\n",
       "      <td>bert-base-uncased-mix</td>\n",
       "      <td>/nfs/jiant/exp/iftenney/20190721-test-ep-bert/...</td>\n",
       "      <td>spr2</td>\n",
       "      <td>test</td>\n",
       "      <td>_micro_avg_</td>\n",
       "      <td>750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.848810</td>\n",
       "      <td>0.826188</td>\n",
       "      <td>0.837346</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.010834</td>\n",
       "      <td>0.011307</td>\n",
       "      <td>0.011066</td>\n",
       "      <td>0.837346</td>\n",
       "      <td>0.011066</td>\n",
       "      <td>spr2-_micro_avg_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>base</td>\n",
       "      <td>None</td>\n",
       "      <td>bert-base-uncased-lex-edges-coref-ontonotes</td>\n",
       "      <td>None</td>\n",
       "      <td>bert-base-uncased-lex</td>\n",
       "      <td>/nfs/jiant/exp/iftenney/20190721-test-ep-bert-...</td>\n",
       "      <td>coref-ontonotes</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>1666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.767659</td>\n",
       "      <td>0.723440</td>\n",
       "      <td>0.744894</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.010986</td>\n",
       "      <td>0.011296</td>\n",
       "      <td>0.011139</td>\n",
       "      <td>0.744894</td>\n",
       "      <td>0.011139</td>\n",
       "      <td>coref-ontonotes-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>base</td>\n",
       "      <td>None</td>\n",
       "      <td>bert-base-uncased-mix-edges-coref-ontonotes</td>\n",
       "      <td>None</td>\n",
       "      <td>bert-base-uncased-mix</td>\n",
       "      <td>/nfs/jiant/exp/iftenney/20190721-test-ep-bert-...</td>\n",
       "      <td>coref-ontonotes</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.893441</td>\n",
       "      <td>0.915837</td>\n",
       "      <td>0.904500</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.007696</td>\n",
       "      <td>0.007011</td>\n",
       "      <td>0.007338</td>\n",
       "      <td>0.904500</td>\n",
       "      <td>0.007338</td>\n",
       "      <td>coref-ontonotes-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>base</td>\n",
       "      <td>None</td>\n",
       "      <td>bert-base-uncased-lex-edges-ner-ontonotes</td>\n",
       "      <td>None</td>\n",
       "      <td>bert-base-uncased-lex</td>\n",
       "      <td>/nfs/jiant/exp/iftenney/20190721-test-ep-bert-...</td>\n",
       "      <td>ner-ontonotes</td>\n",
       "      <td>test</td>\n",
       "      <td>_micro_avg_</td>\n",
       "      <td>1374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928761</td>\n",
       "      <td>0.890831</td>\n",
       "      <td>0.909401</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.004589</td>\n",
       "      <td>0.005448</td>\n",
       "      <td>0.004982</td>\n",
       "      <td>0.909401</td>\n",
       "      <td>0.004982</td>\n",
       "      <td>ner-ontonotes-_micro_avg_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>base</td>\n",
       "      <td>None</td>\n",
       "      <td>bert-base-uncased-mix-edges-ner-ontonotes</td>\n",
       "      <td>None</td>\n",
       "      <td>bert-base-uncased-mix</td>\n",
       "      <td>/nfs/jiant/exp/iftenney/20190721-test-ep-bert-...</td>\n",
       "      <td>ner-ontonotes</td>\n",
       "      <td>test</td>\n",
       "      <td>_micro_avg_</td>\n",
       "      <td>550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968147</td>\n",
       "      <td>0.956301</td>\n",
       "      <td>0.962187</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.003087</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>0.003312</td>\n",
       "      <td>0.962187</td>\n",
       "      <td>0.003312</td>\n",
       "      <td>ner-ontonotes-_micro_avg_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>base</td>\n",
       "      <td>None</td>\n",
       "      <td>bert-base-uncased-lex-edges-srl-ontonotes</td>\n",
       "      <td>None</td>\n",
       "      <td>bert-base-uncased-lex</td>\n",
       "      <td>/nfs/jiant/exp/iftenney/20190721-test-ep-bert-...</td>\n",
       "      <td>srl-ontonotes</td>\n",
       "      <td>test</td>\n",
       "      <td>_core_</td>\n",
       "      <td>12281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795270</td>\n",
       "      <td>0.705753</td>\n",
       "      <td>0.747842</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>0.747842</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>srl-ontonotes-_core_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>base</td>\n",
       "      <td>None</td>\n",
       "      <td>bert-base-uncased-mix-edges-srl-ontonotes</td>\n",
       "      <td>None</td>\n",
       "      <td>bert-base-uncased-mix</td>\n",
       "      <td>/nfs/jiant/exp/iftenney/20190721-test-ep-bert-...</td>\n",
       "      <td>srl-ontonotes</td>\n",
       "      <td>test</td>\n",
       "      <td>_core_</td>\n",
       "      <td>2885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947286</td>\n",
       "      <td>0.930877</td>\n",
       "      <td>0.939010</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.002163</td>\n",
       "      <td>0.002434</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>0.939010</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>srl-ontonotes-_core_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>base</td>\n",
       "      <td>None</td>\n",
       "      <td>bert-base-uncased-lex-edges-srl-ontonotes</td>\n",
       "      <td>None</td>\n",
       "      <td>bert-base-uncased-lex</td>\n",
       "      <td>/nfs/jiant/exp/iftenney/20190721-test-ep-bert-...</td>\n",
       "      <td>srl-ontonotes</td>\n",
       "      <td>test</td>\n",
       "      <td>_non_core_</td>\n",
       "      <td>5932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.883644</td>\n",
       "      <td>0.675634</td>\n",
       "      <td>0.765765</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>0.006785</td>\n",
       "      <td>0.005961</td>\n",
       "      <td>0.765765</td>\n",
       "      <td>0.005961</td>\n",
       "      <td>srl-ontonotes-_non_core_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>base</td>\n",
       "      <td>None</td>\n",
       "      <td>bert-base-uncased-mix-edges-srl-ontonotes</td>\n",
       "      <td>None</td>\n",
       "      <td>bert-base-uncased-mix</td>\n",
       "      <td>/nfs/jiant/exp/iftenney/20190721-test-ep-bert-...</td>\n",
       "      <td>srl-ontonotes</td>\n",
       "      <td>test</td>\n",
       "      <td>_non_core_</td>\n",
       "      <td>3236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.901209</td>\n",
       "      <td>0.823053</td>\n",
       "      <td>0.860360</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>0.004978</td>\n",
       "      <td>0.860360</td>\n",
       "      <td>0.004978</td>\n",
       "      <td>srl-ontonotes-_non_core_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>base</td>\n",
       "      <td>None</td>\n",
       "      <td>bert-base-uncased-lex-edges-srl-ontonotes</td>\n",
       "      <td>None</td>\n",
       "      <td>bert-base-uncased-lex</td>\n",
       "      <td>/nfs/jiant/exp/iftenney/20190721-test-ep-bert-...</td>\n",
       "      <td>srl-ontonotes</td>\n",
       "      <td>test</td>\n",
       "      <td>_clean_micro_</td>\n",
       "      <td>18213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819490</td>\n",
       "      <td>0.696576</td>\n",
       "      <td>0.753051</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.003337</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>0.003499</td>\n",
       "      <td>0.753051</td>\n",
       "      <td>0.003499</td>\n",
       "      <td>srl-ontonotes-_clean_micro_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>base</td>\n",
       "      <td>None</td>\n",
       "      <td>bert-base-uncased-mix-edges-srl-ontonotes</td>\n",
       "      <td>None</td>\n",
       "      <td>bert-base-uncased-mix</td>\n",
       "      <td>/nfs/jiant/exp/iftenney/20190721-test-ep-bert-...</td>\n",
       "      <td>srl-ontonotes</td>\n",
       "      <td>test</td>\n",
       "      <td>_clean_micro_</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933952</td>\n",
       "      <td>0.898026</td>\n",
       "      <td>0.915637</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.002421</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>0.915637</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>srl-ontonotes-_clean_micro_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tag  seed                                     exp_name layer_num  \\\n",
       "0   base  None      bert-base-uncased-lex-edges-rel-semeval      None   \n",
       "1   base  None      bert-base-uncased-mix-edges-rel-semeval      None   \n",
       "2   base  None             bert-base-uncased-lex-edges-spr2      None   \n",
       "3   base  None             bert-base-uncased-mix-edges-spr2      None   \n",
       "4   base  None  bert-base-uncased-lex-edges-coref-ontonotes      None   \n",
       "5   base  None  bert-base-uncased-mix-edges-coref-ontonotes      None   \n",
       "6   base  None    bert-base-uncased-lex-edges-ner-ontonotes      None   \n",
       "7   base  None    bert-base-uncased-mix-edges-ner-ontonotes      None   \n",
       "8   base  None    bert-base-uncased-lex-edges-srl-ontonotes      None   \n",
       "9   base  None    bert-base-uncased-mix-edges-srl-ontonotes      None   \n",
       "10  base  None    bert-base-uncased-lex-edges-srl-ontonotes      None   \n",
       "11  base  None    bert-base-uncased-mix-edges-srl-ontonotes      None   \n",
       "12  base  None    bert-base-uncased-lex-edges-srl-ontonotes      None   \n",
       "13  base  None    bert-base-uncased-mix-edges-srl-ontonotes      None   \n",
       "\n",
       "                 exp_type                                                run  \\\n",
       "0   bert-base-uncased-lex  /nfs/jiant/exp/iftenney/20190721-test-ep-bert/...   \n",
       "1   bert-base-uncased-mix  /nfs/jiant/exp/iftenney/20190721-test-ep-bert/...   \n",
       "2   bert-base-uncased-lex  /nfs/jiant/exp/iftenney/20190721-test-ep-bert/...   \n",
       "3   bert-base-uncased-mix  /nfs/jiant/exp/iftenney/20190721-test-ep-bert/...   \n",
       "4   bert-base-uncased-lex  /nfs/jiant/exp/iftenney/20190721-test-ep-bert-...   \n",
       "5   bert-base-uncased-mix  /nfs/jiant/exp/iftenney/20190721-test-ep-bert-...   \n",
       "6   bert-base-uncased-lex  /nfs/jiant/exp/iftenney/20190721-test-ep-bert-...   \n",
       "7   bert-base-uncased-mix  /nfs/jiant/exp/iftenney/20190721-test-ep-bert-...   \n",
       "8   bert-base-uncased-lex  /nfs/jiant/exp/iftenney/20190721-test-ep-bert-...   \n",
       "9   bert-base-uncased-mix  /nfs/jiant/exp/iftenney/20190721-test-ep-bert-...   \n",
       "10  bert-base-uncased-lex  /nfs/jiant/exp/iftenney/20190721-test-ep-bert-...   \n",
       "11  bert-base-uncased-mix  /nfs/jiant/exp/iftenney/20190721-test-ep-bert-...   \n",
       "12  bert-base-uncased-lex  /nfs/jiant/exp/iftenney/20190721-test-ep-bert-...   \n",
       "13  bert-base-uncased-mix  /nfs/jiant/exp/iftenney/20190721-test-ep-bert-...   \n",
       "\n",
       "               task split          label  fn_count  \\\n",
       "0       rel-semeval  test  _clean_micro_      1153   \n",
       "1       rel-semeval  test  _clean_micro_       494   \n",
       "2              spr2  test    _micro_avg_       846   \n",
       "3              spr2  test    _micro_avg_       750   \n",
       "4   coref-ontonotes  test              1      1666   \n",
       "5   coref-ontonotes  test              1       507   \n",
       "6     ner-ontonotes  test    _micro_avg_      1374   \n",
       "7     ner-ontonotes  test    _micro_avg_       550   \n",
       "8     srl-ontonotes  test         _core_     12281   \n",
       "9     srl-ontonotes  test         _core_      2885   \n",
       "10    srl-ontonotes  test     _non_core_      5932   \n",
       "11    srl-ontonotes  test     _non_core_      3236   \n",
       "12    srl-ontonotes  test  _clean_micro_     18213   \n",
       "13    srl-ontonotes  test  _clean_micro_      6121   \n",
       "\n",
       "               ...               precision    recall  f1_score  \\\n",
       "0              ...                0.711538  0.490499  0.580696   \n",
       "1              ...                0.864614  0.781706  0.821072   \n",
       "2              ...                0.829507  0.803940  0.816523   \n",
       "3              ...                0.848810  0.826188  0.837346   \n",
       "4              ...                0.767659  0.723440  0.744894   \n",
       "5              ...                0.893441  0.915837  0.904500   \n",
       "6              ...                0.928761  0.890831  0.909401   \n",
       "7              ...                0.968147  0.956301  0.962187   \n",
       "8              ...                0.795270  0.705753  0.747842   \n",
       "9              ...                0.947286  0.930877  0.939010   \n",
       "10             ...                0.883644  0.675634  0.765765   \n",
       "11             ...                0.901209  0.823053  0.860360   \n",
       "12             ...                0.819490  0.696576  0.753051   \n",
       "13             ...                0.933952  0.898026  0.915637   \n",
       "\n",
       "   accuracy_errn95  precision_errn95 recall_errn95  f1_errn95     score  \\\n",
       "0         0.001578          0.022482      0.020597   0.021498  0.580696   \n",
       "1         0.001104          0.014825      0.017020   0.015847  0.821072   \n",
       "2         0.006187          0.011398      0.011846   0.011618  0.816523   \n",
       "3         0.005882          0.010834      0.011307   0.011066  0.837346   \n",
       "4         0.003639          0.010986      0.011296   0.011139  0.744894   \n",
       "5         0.002355          0.007696      0.007011   0.007338  0.904500   \n",
       "6         0.000407          0.004589      0.005448   0.004982  0.909401   \n",
       "7         0.000266          0.003087      0.003571   0.003312  0.962187   \n",
       "8         0.000625          0.004109      0.004372   0.004237  0.747842   \n",
       "9         0.000320          0.002163      0.002434   0.002290  0.939010   \n",
       "10        0.000131          0.005315      0.006785   0.005961  0.765765   \n",
       "11        0.000106          0.004525      0.005531   0.004978  0.860360   \n",
       "12        0.000186          0.003337      0.003678   0.003499  0.753051   \n",
       "13        0.000113          0.002026      0.002421   0.002206  0.915637   \n",
       "\n",
       "    score_errn95                  display_row  \n",
       "0       0.021498    rel-semeval-_clean_micro_  \n",
       "1       0.015847    rel-semeval-_clean_micro_  \n",
       "2       0.011618             spr2-_micro_avg_  \n",
       "3       0.011066             spr2-_micro_avg_  \n",
       "4       0.011139            coref-ontonotes-1  \n",
       "5       0.007338            coref-ontonotes-1  \n",
       "6       0.004982    ner-ontonotes-_micro_avg_  \n",
       "7       0.003312    ner-ontonotes-_micro_avg_  \n",
       "8       0.004237         srl-ontonotes-_core_  \n",
       "9       0.002290         srl-ontonotes-_core_  \n",
       "10      0.005961     srl-ontonotes-_non_core_  \n",
       "11      0.004978     srl-ontonotes-_non_core_  \n",
       "12      0.003499  srl-ontonotes-_clean_micro_  \n",
       "13      0.002206  srl-ontonotes-_clean_micro_  \n",
       "\n",
       "[14 rows x 30 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPLIT = \"test\"\n",
    "# SPLIT = \"val\"\n",
    "mask = df['split'] == SPLIT\n",
    "\n",
    "final_scores = []\n",
    "for task in df['task'].unique():\n",
    "    task_scores = df[mask & (df['task'] == task)]\n",
    "    if analysis.is_coref_task(task):\n",
    "        final_scores.append(task_scores[task_scores['label'] == \"1\"])\n",
    "        # For GAP coref, have stratified by gender\n",
    "        if task.startswith(\"coref-gap\"):\n",
    "            final_scores.append(task_scores[task_scores['label'] == \"_info.pronoun_gender_MASCULINE_1_\"])\n",
    "            final_scores.append(task_scores[task_scores['label'] == \"_info.pronoun_gender_FEMININE_1_\"])\n",
    "    elif task == \"dpr\":\n",
    "        dpr_mask = task_scores['seed'] == \"_mean_\"\n",
    "        dpr_mask &= task_scores['label'] == \"_micro_avg_\"\n",
    "        final_scores.append(task_scores[dpr_mask])\n",
    "    elif analysis.is_srl_task(task):\n",
    "        final_scores.append(task_scores[task_scores['label'] == '_core_'])\n",
    "        final_scores.append(task_scores[task_scores['label'] == '_non_core_'])\n",
    "        # Use clean version, average only over core or noncore roles.\n",
    "        final_scores.append(task_scores[task_scores['label'] == '_clean_micro_'])\n",
    "    elif analysis.is_relation_task(task):\n",
    "        # Relation tasks include specific \"no_relation\" label\n",
    "        final_scores.append(task_scores[task_scores['label'] == '_clean_micro_'])\n",
    "    elif task == \"noun-verb\":\n",
    "        # Noun-verb reports accuracy on VERB class\n",
    "        final_scores.append(task_scores[task_scores['label'] == 'VERB'])\n",
    "    else:\n",
    "        final_scores.append(task_scores[task_scores['label'] == '_micro_avg_'])\n",
    "        \n",
    "fdf = pd.concat(final_scores, axis=0, ignore_index=True, sort=False)\n",
    "# fdf['task_and_metric'] = [\"%s-%s\" % tl for tl in zip(fdf.task, fdf.label)]\n",
    "def format_display_row(task, label, seed):\n",
    "    ret = f\"{task}-{label}\"\n",
    "    if seed:\n",
    "        ret += f\":{seed}\"\n",
    "    return ret\n",
    "\n",
    "fdf['display_row'] = [format_display_row(*args) for args in zip(fdf.task, fdf.label, fdf.seed)]\n",
    "print(len(fdf))\n",
    "fdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot DataFrame to present each task on a row, and each experiment on a column.\n",
    "\n",
    "This form is suitable to copy-paste into a spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "display_row,bert-base-uncased-lex (base),bert-base-uncased-mix (base)\n",
      "ner-ontonotes-_micro_avg_,90.9401,96.2187\n",
      "srl-ontonotes-_clean_micro_,75.3051,91.5637\n",
      "srl-ontonotes-_core_,74.7842,93.9010\n",
      "srl-ontonotes-_non_core_,76.5765,86.0360\n",
      "coref-ontonotes-1,74.4894,90.4500\n",
      "spr2-_micro_avg_,81.6523,83.7346\n",
      "rel-semeval-_clean_micro_,58.0696,82.1072\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pivot to wide-form for spreadsheet, and sort in (mostly) stable order.\n",
    "sheet_df = fdf.pivot(index=\"display_row\", columns=\"display_col\", values=\"score\")\n",
    "sheet_df = sheet_df.reindex(sorted(sheet_df.columns, \n",
    "                                   key=exp_type_sort_key), axis=1)\n",
    "sheet_df = sheet_df.reindex(sorted(sheet_df.index,\n",
    "                                   key=task_sort_key), axis=0)\n",
    "# sheet_df\n",
    "print((100*sheet_df).to_csv(**csv_args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the same format, but show the 95% confidence intervals for each score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "display_row,bert-base-uncased-lex (base),bert-base-uncased-mix (base)\n",
      "ner-ontonotes-_micro_avg_,0.4982,0.3312\n",
      "srl-ontonotes-_clean_micro_,0.3499,0.2206\n",
      "srl-ontonotes-_core_,0.4237,0.2290\n",
      "srl-ontonotes-_non_core_,0.5961,0.4978\n",
      "coref-ontonotes-1,1.1139,0.7338\n",
      "spr2-_micro_avg_,1.1618,1.1066\n",
      "rel-semeval-_clean_micro_,2.1498,1.5847\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sheet_df = fdf.pivot(index=\"display_row\", columns=\"display_col\", values=\"score_errn95\")\n",
    "sheet_df = sheet_df.reindex(sorted(sheet_df.columns, \n",
    "                                   key=exp_type_sort_key), axis=1)\n",
    "sheet_df = sheet_df.reindex(sorted(sheet_df.index,\n",
    "                                   key=task_sort_key), axis=0)\n",
    "# sheet_df\n",
    "print((100*sheet_df).to_csv(**csv_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jiant",
   "language": "python",
   "name": "jiant"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
