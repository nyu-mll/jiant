// This imports the defaults, which can be overridden below.
include "../defaults.conf"
include "final_bert.conf"  // relative path to this file

project_dir = ${JIANT_PROJECT_PREFIX}
exp_name = "bert_base_cased"  // configure this
run_name = "bert_small_rnn_sent_enc"  // default

pretrain_tasks = "gap-coreference"  // empty: don't run main training phase
target_tasks = "gap-coreference"   // train classifier only

// Eval will use task-specific params.
do_pretrain = 1       // skip main train phase
do_target_task_training = 0  // train using eval task params
do_full_eval = 0
write_preds = "val,test"
allow_reuse_of_pretraining_parameters = 0 

reload_tasks = 1
reload_vocab = 1
reload_index = 1
elmo = 0 
reindex_tasks = "gap-coreference"
load_model = 0
bert_model_name = "bert-base-cased"
tokenizer = ${bert_model_name}
bert_fine_tune = 1
batch_size = 8
max_seq_len = 511

sent_enc = "rnn"
skip_embs = 1  // forward embeddings from lower level. 
sep_embs_for_skip = 0 
classifier_loss_fn = "sigmoid"




