// Run elmo model on cola-analysis dataset 
// 
include "defaults.conf"


// Do not change

random_seed = 42
word_embs_file = ""
fastText_model_file = ""

// Paths

exp_name = debug  // avoid messing up other experiment records
run_name = debug  // overwrite this when running models

// Data setting

reload_vocab = 1
reload_tasks = 1
reload_indexing = 1
reindex_tasks = cola-analysis

// Training setting

load_model = 0

pretrain_tasks = cola-analysis
do_pretrain = 1  // train the model on top of embedding layer

target_tasks = cola-analysis
do_target_task_training = 1  // tune the parameters on target task
do_full_eval = 1  // evaluation the model after training

lr = 3e-4  // this performs reasonablely well in practice
allow_untrained_encoder_parameters = 0  // set this to 1 when running random-elmo
allow_reuse_of_pretraining_parameters = 1
lr_patience = 4  // number of epoches between last validation improvement and lr annealing 
patience = 20  // numberof epoches between last validation improvement and early stopping
max_vals = 10000

// Eval setting

write_preds = 'test'


// Model settings

elmo = 1
elmo_chars_only = 0
sep_embs_for_skip = 1