// An example configuration for the CommitmentBank task with BERT.
// Run with:
//   python main.py --config_file config/cb_bert.conf

// This imports the defaults, which can be overridden below.
include "defaults.conf"

// Basics
exp_name = copa_with_bert
list_params = 0  // Quieter logs, since we're not experimenting with new or exciting architectures.

// Standard setup for training on a single target task.
pretrain_tasks = copa
target_tasks = copa
do_pretrain = 1
do_target_task_training = 0
do_full_eval = 1

// BERT setup
transfer_paradigm = finetune
batch_size = 16
optimizer = bert_adam
lr = 0.00003  // Typical initial learning rate.
bert_model_name = bert-base-uncased
sent_enc = none
sep_embs_for_skip = 1
tokenizer = bert-base-uncased
classifier = log_reg

// Trainer setup for small tasks with BERT
val_interval = 25
max_epochs = 4
dropout = 0.1

// Preprocessing
max_seq_len = 128


