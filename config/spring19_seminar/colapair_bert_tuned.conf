// Load trained bert model and evalute on minimal pair task

include "bert.conf"


// Paths

exp_name = debug  // avoid messing up other experiment records
run_name = debug  // override exp_name and run_name when training new models

// Training setting

pretrain_tasks = ""  // we can choose pretrain the model on cola task 
do_pretrain = 0  // but not in frozen setting

target_tasks = cola-pair-tuned
do_target_task_training = 0  // do not tune the parameters on target task

transfer_paradigm = "finetune"
write_preds = "val"

