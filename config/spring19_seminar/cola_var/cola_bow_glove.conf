// Import the defaults using the relative path
include "../final.conf"


// Output path
project_dir = ${JIANT_PROJECT_PREFIX}


// Optimization
batch_size = 16
dropout = 0.1 // following BERT paper
lr = 2e-5  // following Jason, Alex


// Target tasks
do_target_task_training = 1  // If true, after do_pretrain train the task-specific model parameters
write_preds = "val,test"  // 0 for none, or comma-separated splits in {"train", "val", "test"} 
                          // for which predictions are written to disk during do_full_eval


// Pretraining tasks
load_model = 0  // If true, restore from checkpoint when starting do_pretrain


// Models
// Model, bow + GloVe
tokenizer = "MosesTokenizer" // The default tokenizer
sent_enc = "bow" // "bow", "rnn" for LSTM, "null"
word_embs = "glove"
elmo = 0
elmo_chars_only = 0